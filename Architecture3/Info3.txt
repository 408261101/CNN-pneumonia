1.神經結構：
class LeNetCNN(nn.Module):
    def __init__(self):
        super(LeNetCNN, self).__init__()
        # 定義卷積層
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5, padding=2)
        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, padding=2)
        self.conv3 = nn.Conv2d(in_channels=50, out_channels=100, kernel_size=5, padding=2)

        # 定義平均池化層
        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)

        # 定義全連接層
        # 調整全連接層輸入特徵數，考慮到輸入圖像大小為256x256，經過3個卷積和池化層後的尺寸
        self.fc1 = nn.Linear(in_features=100 * 32 * 32, out_features=500)  # 256x256 -> 128x128 -> 64x64 -> 32x32
        self.fc2 = nn.Linear(in_features=500, out_features=100)
        self.fc3 = nn.Linear(in_features=100, out_features=2)  # 最終輸出類別為2

        # 定義 Dropout 層
        self.dropout = nn.Dropout(p=0.5)

    def forward(self, x):
        # 通過卷積層和激活層
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = F.relu(self.conv3(x))
        x = self.pool(x)

        # 展平特徵圖以便輸入到全連接層
        x = x.view(-1, 100 * 32 * 32)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


2.模型總參數量
   51402472

3.卷積層參數量
    151670

4.全連接層參數量
    51250802

5.優化器
    Adam

6.學習率
    0.001